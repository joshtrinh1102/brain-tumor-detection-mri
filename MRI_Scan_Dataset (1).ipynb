{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries\n"
      ],
      "metadata": {
        "id": "sKx12Gc6qLOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install tensorflow numpy matplotlib opencv-python"
      ],
      "metadata": {
        "id": "rEF4sndfB151"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,precision_recall_curve,\n",
        "                             accuracy_score, precision_score, recall_score, auc,\n",
        "                             f1_score, roc_auc_score, roc_curve, precision_recall_fscore_support)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (BaggingClassifier, RandomForestClassifier,\n",
        "                              AdaBoostClassifier, GradientBoostingClassifier,\n",
        "                              VotingClassifier, StackingClassifier)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Initialize the Brain\n",
        "model = models.Sequential()\n",
        "\n",
        "# 2. The \"Eyes\" (Convolutional Layers)\n",
        "# Look for 32 different features (edges/shapes) using a 3x3 filter\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2))) # Shrink the image (focus on what matters)\n",
        "\n",
        "# Look for 64 more complex features\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# 3. The \"Thinking\" (Dense Layers)\n",
        "model.add(layers.Flatten()) # Flatten the 2D image into a 1D list of numbers\n",
        "model.add(layers.Dense(64, activation='relu')) # A layer of neurons to think\n",
        "\n",
        "# 4. The Output\n",
        "# 1 neuron. If output is near 0 -> Healthy. If near 1 -> Cancer.\n",
        "model.add(layers.Dense(4, activation='sigmoid'))#1 is for 2 categories, 4 is for 4 categories)"
      ],
      "metadata": {
        "id": "93VvEzPGklVe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Dataset\n"
      ],
      "metadata": {
        "id": "_Hsuo7sLqTG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "file_list = os.listdir(path)\n",
        "print(\"Files in folder:\", file_list)\n",
        "\n",
        "# 1. Setup variables (Constraints)\n",
        "# We resize everything to 150x150 so the CNN doesn't get confused by different sizes.\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "BATCH_SIZE = 32  # The AI learns from 32 images at a time\n",
        "\n",
        "# 2. Load the 'Training' Data\n",
        "print(\"Loading Training Data:\")\n",
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/kaggle/input/brain-tumor-mri-dataset/Training',        # Point to the folder\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical',   # Use 'categorical' because you have 4 folder types\n",
        "    shuffle=True                # Shuffle so the AI doesn't memorize the order\n",
        ")\n",
        "\n",
        "# 3. Load the 'Testing' Data (Validation)\n",
        "print(\"\\nLoading Testing Data:\")\n",
        "test = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/kaggle/input/brain-tumor-mri-dataset/Testing',\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 4. Check the class names (The folders it found)\n",
        "class_names = train.class_names\n",
        "print(f\"\\nClasses found: {class_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VGdn6AGmUec",
        "outputId": "68185f46-600c-42aa-ea7d-a50f4aa1bb6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'brain-tumor-mri-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/brain-tumor-mri-dataset\n",
            "Files in folder: ['Training', 'Testing']\n",
            "Loading Training Data:\n",
            "Found 5712 files belonging to 4 classes.\n",
            "\n",
            "Loading Testing Data:\n",
            "Found 1311 files belonging to 4 classes.\n",
            "\n",
            "Classes found: ['glioma', 'meningioma', 'notumor', 'pituitary']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-trained model test:"
      ],
      "metadata": {
        "id": "poQDdXiZrQuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define data augmentation FIRST\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomBrightness(0.2),\n",
        "    layers.RandomContrast(0.2),\n",
        "])\n",
        "\n",
        "# 2. Choose ONE model approach - Transfer Learning (recommended)\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(150, 150, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False  # Freeze pre-trained weights initially\n",
        "\n",
        "model = models.Sequential([\n",
        "    data_augmentation,\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# 3. Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Set up callback\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-7\n",
        ")\n",
        "\n",
        "# 5. Train\n",
        "history = model.fit(\n",
        "    train,\n",
        "    validation_data=test,\n",
        "    epochs=30,\n",
        "    callbacks=[reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNMHWLverM6z",
        "outputId": "e4804624-4e16-4f85-f634-da119b854be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 69ms/step - accuracy: 0.4044 - loss: 1.5759 - val_accuracy: 0.4920 - val_loss: 1.1004 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - accuracy: 0.5652 - loss: 1.0045 - val_accuracy: 0.5225 - val_loss: 1.0512 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.6055 - loss: 0.9560 - val_accuracy: 0.5675 - val_loss: 0.9917 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.6172 - loss: 0.9281 - val_accuracy: 0.4989 - val_loss: 1.0675 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.6294 - loss: 0.8913 - val_accuracy: 0.5271 - val_loss: 1.0198 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.6279 - loss: 0.8950 - val_accuracy: 0.5240 - val_loss: 1.0236 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.6387 - loss: 0.8751 - val_accuracy: 0.4790 - val_loss: 1.1216 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.6635 - loss: 0.8321 - val_accuracy: 0.5042 - val_loss: 1.0747 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.6577 - loss: 0.8312 - val_accuracy: 0.5080 - val_loss: 1.0961 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.6522 - loss: 0.8368 - val_accuracy: 0.5027 - val_loss: 1.0681 - learning_rate: 2.5000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.6700 - loss: 0.8221 - val_accuracy: 0.5004 - val_loss: 1.0714 - learning_rate: 2.5000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.6792 - loss: 0.7944 - val_accuracy: 0.4996 - val_loss: 1.0702 - learning_rate: 2.5000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.6679 - loss: 0.8091 - val_accuracy: 0.4996 - val_loss: 1.0864 - learning_rate: 1.2500e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.6620 - loss: 0.8177 - val_accuracy: 0.4928 - val_loss: 1.1031 - learning_rate: 1.2500e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.6751 - loss: 0.8003 - val_accuracy: 0.5088 - val_loss: 1.0699 - learning_rate: 1.2500e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.6821 - loss: 0.8157 - val_accuracy: 0.4943 - val_loss: 1.1057 - learning_rate: 6.2500e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.6641 - loss: 0.8112 - val_accuracy: 0.5011 - val_loss: 1.0943 - learning_rate: 6.2500e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.6683 - loss: 0.8089 - val_accuracy: 0.4966 - val_loss: 1.0842 - learning_rate: 6.2500e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.6856 - loss: 0.7874 - val_accuracy: 0.4966 - val_loss: 1.0802 - learning_rate: 3.1250e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.6732 - loss: 0.7922 - val_accuracy: 0.4989 - val_loss: 1.0806 - learning_rate: 3.1250e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.6854 - loss: 0.7971 - val_accuracy: 0.4966 - val_loss: 1.0844 - learning_rate: 3.1250e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.6853 - loss: 0.7971 - val_accuracy: 0.4981 - val_loss: 1.0816 - learning_rate: 1.5625e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.6788 - loss: 0.7964 - val_accuracy: 0.5004 - val_loss: 1.0766 - learning_rate: 1.5625e-05\n",
            "Epoch 24/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.6743 - loss: 0.7902 - val_accuracy: 0.5019 - val_loss: 1.0735 - learning_rate: 1.5625e-05\n",
            "Epoch 25/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.6695 - loss: 0.8031 - val_accuracy: 0.5011 - val_loss: 1.0736 - learning_rate: 7.8125e-06\n",
            "Epoch 26/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.6657 - loss: 0.8134 - val_accuracy: 0.5019 - val_loss: 1.0693 - learning_rate: 7.8125e-06\n",
            "Epoch 27/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.6848 - loss: 0.7780 - val_accuracy: 0.5027 - val_loss: 1.0718 - learning_rate: 7.8125e-06\n",
            "Epoch 28/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.6687 - loss: 0.7970 - val_accuracy: 0.5004 - val_loss: 1.0738 - learning_rate: 3.9063e-06\n",
            "Epoch 29/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.6786 - loss: 0.8117 - val_accuracy: 0.5004 - val_loss: 1.0746 - learning_rate: 3.9063e-06\n",
            "Epoch 30/30\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.6892 - loss: 0.7864 - val_accuracy: 0.5011 - val_loss: 1.0739 - learning_rate: 3.9063e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train\n"
      ],
      "metadata": {
        "id": "5D-yeZfZqWu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal\", input_shape=(150, 150, 3)),\n",
        "  layers.RandomRotation(0.1),\n",
        "  layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "model = models.Sequential([\n",
        "  # 1. The Augmentation Block (New!)\n",
        "  data_augmentation,\n",
        "\n",
        "  # 2. Convolution Layer 1\n",
        "  layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "  layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "  # 3. Convolution Layer 2\n",
        "  layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "  # 4. Convolution Layer 3 (Added for more depth)\n",
        "  layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "  layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "  # 5. Flatten & Dense\n",
        "  layers.Flatten(),\n",
        "  layers.Dropout(0.5),  # <--- DROPOUT: Kills 50% of neurons randomly to prevent memorization\n",
        "  layers.Dense(128, activation='relu'),\n",
        "\n",
        "  # 6. Output (4 classes)\n",
        "  layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train for a bit longer since the problem is harder now\n",
        "history = model.fit(train, validation_data=test, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ1ZK8-HlFCx",
        "outputId": "325c89ea-0c4c-4b62-d0e6-72ab2540e7bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 97ms/step - accuracy: 0.4919 - loss: 16.9026 - val_accuracy: 0.7063 - val_loss: 0.8379\n",
            "Epoch 2/15\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.6746 - loss: 0.8234 - val_accuracy: 0.6842 - val_loss: 1.1986\n",
            "Epoch 3/15\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.7534 - loss: 0.6466 - val_accuracy: 0.7635 - val_loss: 0.6553\n",
            "Epoch 4/15\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.7679 - loss: 0.5987 - val_accuracy: 0.7117 - val_loss: 0.8714\n",
            "Epoch 5/15\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.7925 - loss: 0.5464 - val_accuracy: 0.7750 - val_loss: 0.6094\n",
            "Epoch 6/15\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.8057 - loss: 0.5069 - val_accuracy: 0.7277 - val_loss: 0.7530\n",
            "Epoch 7/15\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8270 - loss: 0.4583"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test\n"
      ],
      "metadata": {
        "id": "1bVpN1OnqaOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "print(\"Evaluating model...\")\n",
        "test_loss, test_acc = model.evaluate(test)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "SjQGnAwcomgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Test\n"
      ],
      "metadata": {
        "id": "kc-TP1reqcwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- THE FIX: Chain .shuffle() before .take() ---\n",
        "# buffer_size=1000 means \"mix up 1000 images before picking a batch\"\n",
        "for images, labels in test.shuffle(1000).take(1):\n",
        "\n",
        "    # 1. Pick a RANDOM index from this batch (instead of always index 0)\n",
        "    # 'images' usually has 32 items. We pick a random number between 0 and 31.\n",
        "    random_index = np.random.randint(0, len(images))\n",
        "\n",
        "    # 2. Grab that specific random image\n",
        "    img = images[random_index].numpy().astype(\"uint8\")\n",
        "    actual_label_index = np.argmax(labels[random_index])\n",
        "\n",
        "    # 3. Predict\n",
        "    img_prediction = tf.expand_dims(images[random_index], 0)\n",
        "    predictions = model.predict(img_prediction)\n",
        "    predicted_label_index = np.argmax(predictions)\n",
        "\n",
        "    # 4. Show result\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Actual: {class_names[actual_label_index]} \\nAI Pred: {class_names[predicted_label_index]}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "m86EH4kuopXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model"
      ],
      "metadata": {
        "id": "Z2EKOYf3qe45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model as a single file\n",
        "model.save('mri_tumor_detector.keras')\n",
        "print(\"Model saved! Check your file browser on the left.\")"
      ],
      "metadata": {
        "id": "NHyvEPBjorGP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}